\documentclass[a4paper]{article}

\usepackage{enumitem}
\usepackage{natbib}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{graphicx}
\usepackage{listings}
\usepackage[hyphens]{url}
\usepackage{titling}
\usepackage{varwidth}
\usepackage{hyperref}
\usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}


\usepackage{geometry}
 \geometry{
 a4paper,
 total={165mm,257mm},
 left=20mm,
 top=20mm,
 }

\title{Research Seminar in Data Science\\Review of a conference paper}
\author{
  Christoph Schmidl\\ s4226887\\      \texttt{c.schmidl@student.ru.nl}
}
\date{\today}
\date{\today}

\begin{document}
\maketitle





\section{Causal Inference in Time Series via Supervised Learning}

\subsection{Summary (not part of the review paper template)}

On the 14th June 2018 Taco Cohen who is a machine learning researcher at Qualcomm and is finishing his PhD in Machine Learning at the University of Amsterdam gave a presentation named "Equivariant Neural Networks" on the first Deep Learning Nijmegen Meetup.\\ 
Equivariant Neural Networks is the short term for Group equivariant Convolutional Neural Networks (G-CNNs) which are using G-convolutions (Group Convolutions) as their main building block and is based on his paper published in 2016 \cite{cohen2016group}. G-convolutions seem to be easy to use and do not introduce additonal computational overhead for discrete groups which are generated by translations, reflections and rotations of the samples. This newly introduced type of Group convolution layers makes it possible to exploit larger groups of symmetries and therefore makes the usage of some data augmentation techniques obsolete. Taco went through the technical details of equivariant neural networks and later on presented how his technique was used by other researchers in different domains.\\


\subsection{Topics to look up (not part of the review paper template)}

\begin{itemize}

	\item i.i.d. data = Independent and identically distributed random variables
		\begin{itemize}
			\item \textit{In probability theory and statistics, a sequence or other collection of random variables is independent and identically distributed (i.i.d. or iid or IID) if each random variable has the same probability distribution as the others and all are mutually independent.}
		\end{itemize}

	\item Granger causality
		\begin{itemize}
			\item Useful info.	
		\end{itemize}			
	
	
	\item Similar research to causal inference in time series
		\begin{itemize}
			\item Useful info.	
		\end{itemize}			
	
	
	\item Kernel Mean Embedding
		\begin{itemize}
			\item Useful info.	
		\end{itemize}			
	
	
	
	\item Reproducing Kernel Hilbert Space (RKHS)
		\begin{itemize}
			\item Useful info.	
		\end{itemize}			
	
	
	
	\item Maximum Mean discrepancy (MMD): See Paper "A kernel method for the two-sample problem"
		\begin{itemize}
			\item Useful info.	
		\end{itemize}			
	
	
	\item Traditional methods for identifying granger causality: Regression models such as vector autoregressive model (VAR) nad the Generalized Additive Model (GAM)
	\item Kernel Kalman Filter
	\item Conditional Embedding Operator (KKF-CEO)
\end{itemize}



\subsection{Relevance}




\begin{enumerate}[label=(\alph*)]
	\item Is the paper fully withing the scope of the conference?
		\begin{itemize}
			\item \textbf{Answer:}	The "Call for papers"-section on the website of the 27th International Joint Conference on Artificial Intelligence and the 23rd European Conference on Artificial Intelligence \url{https://www.ijcai-18.org/cfp/} states that \textit{"IJCAI-ECAI 2018 welcomes submissions across all areas of AI. The conference scope includes all subareas of AI, including (but not limited to) traditional topics such as machine learning, search, planning, knowledge representation, reasoning, constraint satisfaction, natural language processing, robotics and perception, and multiagent systems. We expressly encourage work that cuts across technical areas and/or integrated capabilities. We encourage all types of contributions including theoretical, engineering and applied. We also encourage papers on AI techniques in the context of novel application domains, such as security, sustainability, health care, transportation, and commerce."} Based on this description and the topic of the paper which is about using supervised (machine) learning techniques in order to do causal inference in time series, I would say that this paper fully fits into the scope of the conference.
		\end{itemize}				
		
		
	\item Will the questions and results of the paper be of interest to researchers in the field?
		\begin{itemize}
			\item \textbf{Answer:} Given the fact that there does not seem to be a lot of prior research and solutions addressing the same problem of treating causal inference in time series as a classification problem, I would assume that this paper is of high interest.
		\end{itemize}			
	
	
	\item Did the authors ignore (or appear unaware of) highly relevant prior work?
		\begin{itemize}
			\item \textbf{Answer:} The paper "Supervised Estimation of Granger-Based Causality between Time Series" \cite{benozzo2017supervised} seems to be highly relevant but was not cited. The paper "Parametric and non-parametric criteria for causal inference from time-series" \cite{chicharro2014parametric} seems relevant but was not cited.
		\end{itemize}			
	
	\item Is previous work in the area of the paper properly cited?
		\begin{itemize}
			\item \textbf{Answer:} Previous work has been briefly mentioned in one sentence in secion "1 - Introduction" by stating that there has been prior work which uses classification to infer causal relationships from i.i.d. data. The mentioned sources are namely:
			
			\begin{enumerate}[label=\Roman*]
				\item A paper called "From dependency to causality: a machine learning approach"  \cite{bontempi2015dependency}. According to google scholar it has been cited only 3 times.
				\item A Kaggle competition called "Cause-effect pairs" which can be found at \url{https://www.kaggle.com/c/cause-effect-pairs}. Instead of just citing the Kaggle competition, it would be better to cite the published papers or code repositories of the winners of the competition. Otherwise the reader has to browse though the Kaggle forum to find the actual results. The first three winners published their code in the following Github repositories:
				\begin{itemize}
					\item Team ProtoML \url{https://github.com/diogo149/CauseEffectPairsChallenge}
					\item Team jarfo \url{https://github.com/jarfo/cause-effect}
					\item Team FirfiD \url{https://github.com/ssamot/causality}
				\end{itemize}
				
								\item A paper called "Towards a learning theory of cause-effect inference" \cite{lopez2015towards}. According to google scholar it has been cited 47 times.
				\item A paper called "Discovering causal signals in images" \cite{lopez2017discovering}. According to google scholar it has been cited 13 times.
			\end{enumerate}
			
			In section "4 - Related Work", it is mentioned that \cite{lopez2015towards} is also using a supervised learning method for i.i.d. data called "Randomized Causation Coefficient (RCC)" which is using kernel mean embedding to obtain features. One sentence is dedicated to describe the difference between the work of \cite{lopez2015towards} and the proposed approach. Previous work has been cited properly but is sparse. In my opinion the citation to the Kaggle competition needs improvement in terms of adding details to the winning solutions.
			
		\end{itemize}		
\end{enumerate}


\subsection{Significance}

\begin{enumerate}[label=(\alph*)]
	\item Is this a significant advance in the state of the art?
		\begin{itemize}
			\item \textbf{Answer:} I would say it is not a significant advance. I also miss the statement of beating state-of-the-art approaches in the conclusion.
		\end{itemize}			
	
	\item Is this a paper that people are likely to read and cite?
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}			
	
	\item Does the paper address an important problem?
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}			
	
	\item Does it open new research directions?
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}			
	
	\item Is it a paper that is likely to have a lasting impact?
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}		
\end{enumerate}

\subsection{Originality}

\begin{itemize}
	\item Reviewers should recognise and reward papers that propose genuinely new ideas. As a reviewer you should try to assess whether the ideas are truly new. Novel combinations, adaptations or extensions of existing ideas are also valuable.
\end{itemize}


\subsection{Technical Quality}

\begin{enumerate}[label=(\alph*)]
	\item Are the results technically sound?
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}			
	
	
	\item Are there obvious flaws in the conceptual approach?
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}		
	
	
	\item Are claims well-supported by theoretical analysis or experimental results?
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}		
	
	\item Are the experiments well thought out and convincing?
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}		
	
	
	\item Will it be possible for other researchers to replicate these results?
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}		
	
	
	\item Is the evaluation appropriate?
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}		
	
	
	\item Did the authors clearly assess both the strenghts and weaknesses of their approach?
		\begin{itemize}
			\item \textbf{Answer:} The authors state that their approach also works with higher dimensional data but on reality it is restricted to three dimensional data. This is a bit misleading.
		\end{itemize}		
	
\end{enumerate}

\subsection{Clarity and quality of writing}

\begin{enumerate}[label=(\alph*)]
	\item Is the paper clearly written?
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}			
	
	
	\item Is there a good use of examples and figures?
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}			
	
	\item Is it well organized?
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}			
	
	
	\item Are these problems with style and grammar?
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}			
	
	
	\item Are these issues with typos, formatting, references, etc.?
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}			
	
	
	
	\item It may be better to advise the authors to revise a paper and submit to a later conference, than to accept and publish a poorly-written version.
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}			
	
	
	
	\item However, if the paper is likely to be accepted, please make suggestions to improve the clarity of the paper, and provide details of typos.
		\begin{itemize}
			\item \textbf{Answer:}	
		\end{itemize}			
	
	
	
\end{enumerate}

\subsection{Scholarship}

\begin{enumerate}[label=(\alph*)]
	\item Does the paper situate the work with respect to the state of the art?
		\begin{itemize}
			\item \textbf{Answer:} Given that \cite{lopez2015towards} is the state-of-the-art, the paper situates the work with respect to the before mentioned paper in a sufficient way. The experiments were chosen in a direct comparison towards Randomized Causation Coefficient.
		\end{itemize}			
	
	
	\item Are relevant papers cited, discussed, and compared to the presented work?
		\begin{itemize}
			\item \textbf{Answer:} Same remark as above although I would question the statement that \cite{lopez2015towards} is the only work which can be used as a direct comparison in the experiments. Furthermore, the related work section seems to be a bit sparse to me. I expected more explicit statements in how far this paper is novel to the other approach. At its core, is there just a difference in the chosen features?
		\end{itemize}			
	
\end{enumerate}

\subsection{Overall Score}

\begin{itemize}
	\item 10 - This is best-paper material
	\item 9 - An excellent paper, a very strong accept
	\item 8 - A very good paper, a strong accept
	\item 7 - A good paper, accept
	\item \textbf{6 - A good paper overall. I vote for acceptance, although would not be upset if it were rejected because of the low acceptance rate}
	\item 5 - Decent paper, but may be below the IJCAI threshold. I tend to vote for rejecting it, although would not be upset if it were accepted.
	\item 4 - I vote for rejecting it, but could be persuaded otherwise.
	\item 3 - A weak paper, just not good enough.
	\item 2 - A clear rejection. I vote and argue for rejection. Clearly below the standards of the conference.
	\item 1 - A very strong rejection. I will actively fight for rejection.
\end{itemize}

\subsection{Confidence on your assessment}

\begin{itemize}
	\item 10 - My own current research is on the topic of the paper
	\item 9 - I have undertaken research on the topic of the paper
	\item 8 - I am an expert in this area
	\item 7 - I have up-to-date knowledge in the area
	\item 6 - I don't have complete knowledge of the area, but can assess the value of the work
	\item 5 - I have a general understanding of the area
	\item \textbf{4 - My assessment is an informed guess}
	\item 3 - My knowledge in the area is limited
	\item 2 - My knowledge in the area is very limited
	\item 1 - My assessment can be wrong
\end{itemize}

\section{Main Review}

\subsection{Comments to Authors. (free text)}

\begin{itemize}
	\item Main body of the review. Make sure you substantiate all the scores for the different criteria above, and refer to the descriptions given.
	\item Give informative content
	\item Be constructive
	\item Write your comments in the same way you would like to receive comments on your own papers.
	\item Include page/line numbers when referring to specific parts.
	\item Add a separate "minor details" section for e.g. (con)textual and/or typographical issues.
\end{itemize}


\subsection{Confidential Comments (Not visible to the authors, only to other reviewers/program char)}

if applicable


\bibliographystyle{apa}
\bibliography{literature} 


\end{document}
