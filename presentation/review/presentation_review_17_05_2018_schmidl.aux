\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Srivastava:2014:DSW:2627435.2670313}
\citation{breiman1996bagging}
\citation{breiman2001random}
\citation{livnat2010sex}
\citation{vincent2008extracting}
\citation{vincent2010stacked}
\citation{Srivastava_improvingneural}
\citation{NIPS2012_4824}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Dropout: A Simple Way to Prevent Neural Networks from Overfitting}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Objective}{1}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Proposal made in the paper}{1}{subsection.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Evidence}{1}{subsection.1.3}}
\citation{DBLP:journals/corr/abs-1207-0580}
\citation{Srivastava_improvingneural}
\citation{DBLP:journals/corr/abs-1207-0580}
\citation{Srivastava:2014:DSW:2627435.2670313}
\citation{breiman1996bagging}
\citation{breiman2001random}
\citation{livnat2010sex}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Shoulders of giants}{2}{subsection.1.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.1}Improving neural networks by preventing co-adaptation of feature detectors}{2}{subsubsection.1.4.1}}
\citation{NIPS2012_4824}
\citation{DBLP:journals/corr/abs-1207-0580}
\citation{DBLP:journals/corr/abs-1207-0580}
\citation{Srivastava_improvingneural}
\citation{DBLP:journals/corr/abs-1207-0580}
\citation{NIPS2012_4824}
\citation{vincent2008extracting}
\citation{vincent2010stacked}
\citation{Srivastava:2014:DSW:2627435.2670313}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.2}ImageNet Classification with Deep Convolutional Neural Networks}{3}{subsubsection.1.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.3}Improving neural networks with dropout}{3}{subsubsection.1.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.4}Dropout: A Simple Way to Prevent Neural Networks from Overfitting}{3}{subsubsection.1.4.4}}
\citation{DBLP:journals/corr/abs-1207-0580}
\citation{wang2013fast}
\citation{wager2013dropout}
\citation{Srivastava:2014:DSW:2627435.2670313}
\citation{wang2013fast}
\citation{ioffe2015batch}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Impact}{4}{subsection.1.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Discussion}{4}{subsection.1.6}}
\citation{wang2013fast}
\bibstyle{apa}
\bibdata{literature}
\bibcite{breiman1996bagging}{{1}{1996}{{Breiman}}{{}}}
\bibcite{breiman2001random}{{2}{2001}{{Breiman}}{{}}}
\bibcite{DBLP:journals/corr/abs-1207-0580}{{3}{2012}{{Hinton et~al.}}{{}}}
\bibcite{ioffe2015batch}{{4}{2015}{{Ioffe and Szegedy}}{{}}}
\bibcite{NIPS2012_4824}{{5}{2012}{{Krizhevsky et~al.}}{{}}}
\bibcite{livnat2010sex}{{6}{2010}{{Livnat et~al.}}{{}}}
\bibcite{Srivastava_improvingneural}{{7}{2013}{{Srivastava}}{{}}}
\bibcite{Srivastava:2014:DSW:2627435.2670313}{{8}{2014}{{Srivastava et~al.}}{{}}}
\bibcite{vincent2008extracting}{{9}{2008}{{Vincent et~al.}}{{}}}
\bibcite{vincent2010stacked}{{10}{2010}{{Vincent et~al.}}{{}}}
\bibcite{wager2013dropout}{{11}{2013}{{Wager et~al.}}{{}}}
\bibcite{wang2013fast}{{12}{2013}{{Wang and Manning}}{{}}}
